# LLM Education Literature Digest

*Generated: 2026-01-05 06:56:30 UTC*

**16 new items**

## 1. Problems With Large Language Models for Learner Modelling: Why LLMs Alone Fall Short for Responsible Tutoring in K--12 Education

**Authors:** Danial Hooshyar, Yeongwook Yang, Gustav Šíř, Tommi Kärkkäinen, Raija Hämäläinen et al. (7 authors)

**Source:** arxiv • 2025-12-28

**Summary:** The rapid rise of large language model (LLM)-based tutors in K--12 education has fostered a misconception that generative models can replace traditional learner modelling for adaptive instruction. This is especially problematic in K--12 settings, which the EU AI Act classifies as high-risk domain re...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23036v1
- PDF: https://arxiv.org/pdf/2512.23036v1

*Relevance score: 17.0*

---

## 2. Measuring University Students Satisfaction with Traditional Search Engines and Generative AI Tools as Information Sources

**Authors:** Brady D. Lund, Scott J. Warren, Zoe A. Teel

**Source:** arxiv • 2026-01-01

**Summary:** This study examines university students levels of satisfaction with generative artificial intelligence (AI) tools and traditional search engines as academic information sources. An electronic survey was distributed to students at U.S. universities in late fall 2025, with 236 valid responses received...

**Links:**
- Landing page: http://arxiv.org/abs/2601.00493v1
- PDF: https://arxiv.org/pdf/2601.00493v1

*Relevance score: 15.0*

---

## 3. Can AI Recognize Its Own Reflection? Self-Detection Performance of LLMs in Computing Education

**Authors:** Christopher Burger, Karmece Talley, Christina Trotter

**Source:** arxiv • 2025-12-29

**Summary:** The rapid advancement of Large Language Models (LLMs) presents a significant challenge to academic integrity within computing education. As educators seek reliable detection methods, this paper evaluates the capacity of three prominent LLMs (GPT-4, Claude, and Gemini) to identify AI-generated text i...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23587v1
- PDF: https://arxiv.org/pdf/2512.23587v1

*Relevance score: 15.0*

---

## 4. Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice

**Authors:** Junyeong Park, Jieun Han, Yeon Su Park, Youngbin Lee, Suin Kim et al. (8 authors)

**Source:** arxiv • 2025-12-29

**Summary:** For English as a Foreign Language (EFL) learners, code-switching (CSW), or alternating between their native language and the target language (English), can lower anxiety and ease communication barriers. Large language models (LLMs), with their multilingual abilities, offer new opportunities to suppo...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23136v1
- PDF: https://arxiv.org/pdf/2512.23136v1

*Relevance score: 15.0*

---

## 5. LLteacher: A Tool for the Integration of Generative AI into Statistics Assignments

**Authors:** Emanuela Furfaro, Simone Mosciatti

**Source:** arxiv • 2025-12-28

**Summary:** As generative AI becomes increasingly embedded in everyday life, the thoughtful and intentional integration of AI-based tools into statistics education has become essential. We address this need with a focus on homework assignments and we propose the use of LLMs as a companion to complete homework b...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23053v1
- PDF: https://arxiv.org/pdf/2512.23053v1

*Relevance score: 15.0*

---

## 6. Grading Handwritten Engineering Exams with Multimodal Large Language Models

**Authors:** Janez Perš, Jon Muhovič, Andrej Košir, Boštjan Murovec

**Source:** arxiv • 2026-01-02

**Summary:** Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, ...

**Links:**
- Landing page: http://arxiv.org/abs/2601.00730v1
- PDF: https://arxiv.org/pdf/2601.00730v1

*Relevance score: 11.0*

---

## 7. User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study

**Authors:** Ananya Bhattacharjee, Jina Suh, Mohit Chandra, Javier Hernandez

**Source:** arxiv • 2026-01-02

**Summary:** Cognitive reappraisal is a well-studied emotion regulation strategy that helps individuals reinterpret stressful situations to reduce their impact. Many digital mental health tools struggle to support this process because rigid scripts fail to accommodate how users naturally describe stressors. This...

**Links:**
- Landing page: http://arxiv.org/abs/2601.00570v1
- PDF: https://arxiv.org/pdf/2601.00570v1

*Relevance score: 11.0*

---

## 8. STELLAR: A Search-Based Testing Framework for Large Language Model Applications

**Authors:** Lev Sorokin, Ivan Vasilev, Ken E. Friedl, Andrea Stocco

**Source:** arxiv • 2026-01-01

**Summary:** Large Language Model (LLM)-based applications are increasingly deployed across various domains, including customer service, education, and mobility. However, these systems are prone to inaccurate, fictitious, or harmful responses, and their vast, high-dimensional input space makes systematic testing...

**Links:**
- Landing page: http://arxiv.org/abs/2601.00497v1
- PDF: https://arxiv.org/pdf/2601.00497v1

*Relevance score: 11.0*

---

## 9. Large language models and the entropy of English

**Authors:** Colin Scheibner, Lindsay M. Smith, William Bialek

**Source:** arxiv • 2025-12-31

**Summary:** We use large language models (LLMs) to uncover long-ranged structure in English texts from a variety of sources. The conditional entropy or code length in many cases continues to decrease with context length at least to $N\sim 10^4$ characters, implying that there are direct dependencies or interact...

**Links:**
- Landing page: http://arxiv.org/abs/2512.24969v1
- PDF: https://arxiv.org/pdf/2512.24969v1

*Relevance score: 11.0*

---

## 10. Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models

**Authors:** Junru Lu, Jiarui Qin, Lingfeng Qiao, Yinghui Li, Xinyi Dai et al. (38 authors)

**Source:** arxiv • 2025-12-31

**Summary:** We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning ca...

**Links:**
- Landing page: http://arxiv.org/abs/2512.24618v1
- PDF: https://arxiv.org/pdf/2512.24618v1

*Relevance score: 11.0*

---

## 11. AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms

**Authors:** LearnLM Team, Eedi, :, Albert Wang, Aliya Rysbek et al. (36 authors)

**Source:** arxiv • 2025-12-29

**Summary:** One-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with $N = 165$ students a...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23633v1
- PDF: https://arxiv.org/pdf/2512.23633v1

*Relevance score: 11.0*

---

## 12. Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation

**Authors:** Manh Hung Nguyen, Adish Singla

**Source:** arxiv • 2025-12-29

**Summary:** Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23601v1
- PDF: https://arxiv.org/pdf/2512.23601v1

*Relevance score: 11.0*

---

## 13. Predicting LLM Correctness in Prosthodontics Using Metadata and Hallucination Signals

**Authors:** Lucky Susanto, Anasta Pranawijayana, Cortino Sukotjo, Soni Prasad, Derry Wijaya

**Source:** arxiv • 2025-12-27

**Summary:** Large language models (LLMs) are increasingly adopted in high-stakes domains such as healthcare and medical education, where the risk of generating factually incorrect (i.e., hallucinated) information is a major concern. While significant efforts have been made to detect and mitigate such hallucinat...

**Links:**
- Landing page: http://arxiv.org/abs/2512.22508v1
- PDF: https://arxiv.org/pdf/2512.22508v1

*Relevance score: 11.0*

---

## 14. Hierarchical Pedagogical Oversight: A Multi-Agent Adversarial Framework for Reliable AI Tutoring

**Authors:** Saisab Sadhu, Ashim Dhor

**Source:** arxiv • 2025-12-27

**Summary:** Large Language Models (LLMs) are increasingly deployed as automated tutors to address educator shortages; however, they often fail at pedagogical reasoning, frequently validating incorrect student solutions (sycophancy) or providing overly direct answers that hinder learning. We introduce Hierarchic...

**Links:**
- Landing page: http://arxiv.org/abs/2512.22496v1
- PDF: https://arxiv.org/pdf/2512.22496v1

*Relevance score: 11.0*

---

## 15. Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection

**Authors:** Quanzhi Fu, Qiyu Wu, Dan Williams

**Source:** arxiv • 2025-12-26

**Summary:** With the significant increase in enrollment in computing-related programs over the past 20 years, lecture sizes have grown correspondingly. In large lectures, instructors face challenges on identifying students' knowledge gaps timely, which is critical for effective teaching. Existing classroom resp...

**Links:**
- Landing page: http://arxiv.org/abs/2512.22404v1
- PDF: https://arxiv.org/pdf/2512.22404v1

*Relevance score: 10.0*

---

## 16. Coding With AI: From a Reflection on Industrial Practices to Future Computer Science and Software Engineering Education

**Authors:** Hung-Fu Chang, MohammadShokrolah Shirazi, Lizhou Cao, Supannika Koolmanojwong Mobasser

**Source:** arxiv • 2025-12-30

**Summary:** Recent advances in large language models (LLMs) have introduced new paradigms in software development, including vibe coding, AI-assisted coding, and agentic coding, fundamentally reshaping how software is designed, implemented, and maintained. Prior research has primarily examined AI-based coding a...

**Links:**
- Landing page: http://arxiv.org/abs/2512.23982v1
- PDF: https://arxiv.org/pdf/2512.23982v1

*Relevance score: 9.0*

---
