# LLM Education Literature Digest

*Generated: 2026-01-26 06:57:11 UTC*

**33 new items**

## 1. DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution

**Authors:** Shengda Fan, Xuyan Ye, Yankai Lin

**Source:** arxiv • 2026-01-20

**Summary:** Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Q...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13761v2
- PDF: https://arxiv.org/pdf/2601.13761v2

*Relevance score: 17.0*

---

## 2. Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction

**Authors:** Xingjie Gao, Pengcheng Huang, Zhenghao Liu, Yukun Yan, Shuo Wang et al. (9 authors)

**Source:** arxiv • 2026-01-19

**Summary:** Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static s...

**Links:**
- Landing page: http://arxiv.org/abs/2601.12762v1
- PDF: https://arxiv.org/pdf/2601.12762v1

*Relevance score: 17.0*

---

## 3. Dataset of GenAI-Assisted Information Problem Solving in Education

**Authors:** Xinyu Li, Kaixun Yang, Jiameng Wei, Yixin Cheng, Dragan Gašević et al. (6 authors)

**Source:** arxiv • 2026-01-19

**Summary:** Information Problem Solving (IPS) is a critical competency for academic and professional success in education, work, and life. The advent of Generative Artificial Intelligence (GenAI), particularly tools like ChatGPT, has introduced new possibilities for supporting students in complex IPS tasks. How...

**Links:**
- Landing page: http://arxiv.org/abs/2601.12718v1
- PDF: https://arxiv.org/pdf/2601.12718v1

*Relevance score: 16.0*

---

## 4. Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks

**Authors:** Dikshya Mohanty, Mohammad Saqib Hasan, Syed Mostofa Monsur, Size Zheng, Benjamin Hsiao et al. (6 authors)

**Source:** arxiv • 2026-01-22

**Summary:** Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to...

**Links:**
- Landing page: http://arxiv.org/abs/2601.16312v1
- PDF: https://arxiv.org/pdf/2601.16312v1

*Relevance score: 15.0*

---

## 5. LLM Prompt Evaluation for Educational Applications

**Authors:** Langdon Holmes, Adam Coscia, Scott Crossley, Joon Suh Choi, Wesley Morris

**Source:** arxiv • 2026-01-22

**Summary:** As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for eva...

**Links:**
- Landing page: http://arxiv.org/abs/2601.16134v1
- PDF: https://arxiv.org/pdf/2601.16134v1

*Relevance score: 15.0*

---

## 6. IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization

**Authors:** Shuai Wang, Yaoming Yang, Bingdong Li, Hao Hao, Aimin Zhou

**Source:** arxiv • 2026-01-21

**Summary:** Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendati...

**Links:**
- Landing page: http://arxiv.org/abs/2601.14686v1
- PDF: https://arxiv.org/pdf/2601.14686v1

*Relevance score: 15.0*

---

## 7. Rewarding How Models Think Pedagogically: Integrating Pedagogical Reasoning and Thinking Rewards for LLMs in Education

**Authors:** Unggi Lee, Jiyeong Bae, Jaehyeon Park, Haeun Park, Taejun Park et al. (10 authors)

**Source:** arxiv • 2026-01-21

**Summary:** Large language models (LLMs) are increasingly deployed as intelligent tutoring systems, yet research on optimizing LLMs specifically for educational contexts remains limited. Recent works have proposed reinforcement learning approaches for training LLM tutors, but these methods focus solely on optim...

**Links:**
- Landing page: http://arxiv.org/abs/2601.14560v1
- PDF: https://arxiv.org/pdf/2601.14560v1

*Relevance score: 15.0*

---

## 8. OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models

**Authors:** Unggi Lee, Sookbun Lee, Heungsoo Choi, Jinseo Lee, Haeun Park et al. (14 authors)

**Source:** arxiv • 2026-01-20

**Summary:** Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment th...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13882v1
- PDF: https://arxiv.org/pdf/2601.13882v1

*Relevance score: 15.0*

---

## 9. CauScientist: Teaching LLMs to Respect Data for Causal Discovery

**Authors:** Bo Peng, Sirui Chen, Lei Xu, Chaochao Lu

**Source:** arxiv • 2026-01-20

**Summary:** Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13614v1
- PDF: https://arxiv.org/pdf/2601.13614v1

*Relevance score: 15.0*

---

## 10. SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics

**Authors:** Santosh Chapagain, MohammadReza EskandariNasab, Onur Vural, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi

**Source:** arxiv • 2026-01-17

**Summary:** Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the import...

**Links:**
- Landing page: http://arxiv.org/abs/2601.12131v1
- PDF: https://arxiv.org/pdf/2601.12131v1

*Relevance score: 15.0*

---

## 11. LLM-based Multimodal Feedback Produces Equivalent Learning and Better Student Perceptions than Educator Feedback

**Authors:** Chloe Qianhui Zhao, Jie Cao, Jionghao Lin, Kenneth R. Koedinger

**Source:** arxiv • 2026-01-21

**Summary:** Providing timely, targeted, and multimodal feedback helps students quickly correct errors, build deep understanding and stay motivated, yet making it at scale remains a challenge. This study introduces a real-time AI-facilitated multimodal feedback system that integrates structured textual explanati...

**Links:**
- Landing page: http://arxiv.org/abs/2601.15280v1
- PDF: https://arxiv.org/pdf/2601.15280v1

*Relevance score: 14.0*

---

## 12. From RTL to Prompt Coding: Empowering the Next Generation of Chip Designers through LLMs

**Authors:** Lukas Krupp, Matthew Venn, Norbert Wehn

**Source:** arxiv • 2026-01-20

**Summary:** This paper presents an LLM-based learning platform for chip design education, aiming to make chip design accessible to beginners without overwhelming them with technical complexity. It represents the first educational platform that assists learners holistically across both frontend and backend desig...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13815v1
- PDF: https://arxiv.org/pdf/2601.13815v1

*Relevance score: 12.0*

---

## 13. Changes in Coding Behavior and Performance Since the Introduction of LLMs

**Authors:** Yufan Zhang, Jaromir Savelka, Seth Copen Goldstein, Michael Conway

**Source:** arxiv • 2026-01-16

**Summary:** The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study...

**Links:**
- Landing page: http://arxiv.org/abs/2601.11835v1
- PDF: https://arxiv.org/pdf/2601.11835v1
- DOI: https://doi.org/10.1145/3785022.3785075

*Relevance score: 12.0*

---

## 14. Persona Jailbreaking in Large Language Models

**Authors:** Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki

**Source:** arxiv • 2026-01-23

**Summary:** Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational histo...

**Links:**
- Landing page: http://arxiv.org/abs/2601.16466v1
- PDF: https://arxiv.org/pdf/2601.16466v1

*Relevance score: 11.0*

---

## 15. Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP

**Authors:** Andres Karjus, Kais Allkivi, Silvia Maine, Katarin Leppik, Krister Kruusmaa et al. (6 authors)

**Source:** arxiv • 2026-01-22

**Summary:** Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a ...

**Links:**
- Landing page: http://arxiv.org/abs/2601.16314v1
- PDF: https://arxiv.org/pdf/2601.16314v1

*Relevance score: 11.0*

---

## 16. Can LLM Reasoning Be Trusted? A Comparative Study: Using Human Benchmarking on Statistical Tasks

**Authors:** Crish Nagarkar, Leonid Bogachev, Serge Sharoff

**Source:** arxiv • 2026-01-20

**Summary:** This paper investigates the ability of large language models (LLMs) to solve statistical tasks, as well as their capacity to assess the quality of reasoning. While state-of-the-art LLMs have demonstrated remarkable performance in a range of NLP tasks, their competence in addressing even moderately c...

**Links:**
- Landing page: http://arxiv.org/abs/2601.14479v1
- PDF: https://arxiv.org/pdf/2601.14479v1

*Relevance score: 11.0*

---

## 17. Zero-Shot Speech LLMs for Multi-Aspect Evaluation of L2 Speech: Challenges and Opportunities

**Authors:** Aditya Kamlesh Parikh, Cristian Tejedor-Garcia, Catia Cucchiarini, Helmer Strik

**Source:** arxiv • 2026-01-20

**Summary:** An accurate assessment of L2 English pronunciation is crucial for language learning, as it provides personalized feedback and ensures a fair evaluation of individual progress. However, automated scoring remains challenging due to the complexity of sentence-level fluency, prosody, and completeness. T...

**Links:**
- Landing page: http://arxiv.org/abs/2601.16230v1
- PDF: https://arxiv.org/pdf/2601.16230v1
- DOI: https://doi.org/10.21437/SLaTE.2025-3

*Relevance score: 11.0*

---

## 18. Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models

**Authors:** Héctor Manuel Manzanilla-Granados, Zaira Navarrete-Cazales, Miriam Pescador-Rojas, Tonahtiu Ramírez-Romero

**Source:** arxiv • 2026-01-19

**Summary:** The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awarenes...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13443v1
- PDF: https://arxiv.org/pdf/2601.13443v1

*Relevance score: 11.0*

---

## 19. Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room

**Authors:** Jacob Barker, Doga Demirel, Cullen Jackson, Anna Johansson, Robbin Miraglia et al. (10 authors)

**Source:** arxiv • 2026-01-19

**Summary:** Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess th...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13406v1
- PDF: https://arxiv.org/pdf/2601.13406v1

*Relevance score: 11.0*

---

## 20. CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning

**Authors:** Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen et al. (6 authors)

**Source:** arxiv • 2026-01-19

**Summary:** While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BE...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13262v1
- PDF: https://arxiv.org/pdf/2601.13262v1

*Relevance score: 11.0*

---

## 21. Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization

**Authors:** Alessandro Midolo, Alessandro Giagnorio, Fiorella Zampetti, Rosalia Tufano, Gabriele Bavota et al. (6 authors)

**Source:** arxiv • 2026-01-19

**Summary:** Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist spe...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13118v1
- PDF: https://arxiv.org/pdf/2601.13118v1

*Relevance score: 11.0*

---

## 22. Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs

**Authors:** Abdellah El Mekki, Samar M. Magdy, Houdaifa Atou, Ruwa AbuHweidi, Baraah Qawasmeh et al. (47 authors)

**Source:** arxiv • 2026-01-19

**Summary:** Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexan...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13099v1
- PDF: https://arxiv.org/pdf/2601.13099v1

*Relevance score: 11.0*

---

## 23. Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation

**Authors:** Jinsook Lee, Kirk Vanacore, Zhuqian Zhou, Bakhtawar Ahtisham, Jeanine Grutter et al. (6 authors)

**Source:** arxiv • 2026-01-17

**Summary:** Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation,...

**Links:**
- Landing page: http://arxiv.org/abs/2601.12061v2
- PDF: https://arxiv.org/pdf/2601.12061v2

*Relevance score: 11.0*

---

## 24. Enhancing LLM-Based Data Annotation with Error Decomposition

**Authors:** Zhen Xu, Vedant Khatri, Yijun Dai, Xiner Liu, Siyan Li et al. (7 authors)

**Source:** arxiv • 2026-01-17

**Summary:** Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as...

**Links:**
- Landing page: http://arxiv.org/abs/2601.11920v1
- PDF: https://arxiv.org/pdf/2601.11920v1

*Relevance score: 11.0*

---

## 25. Large Language Model Agent for User-friendly Chemical Process Simulations

**Authors:** Jingkang Liang, Niklas Groll, Gürkan Sin

**Source:** arxiv • 2026-01-15

**Summary:** Modern process simulators enable detailed process design, simulation, and optimization; however, constructing and interpreting simulations is time-consuming and requires expert knowledge. This limits early exploration by inexperienced users. To address this, a large language model (LLM) agent is int...

**Links:**
- Landing page: http://arxiv.org/abs/2601.11650v1
- PDF: https://arxiv.org/pdf/2601.11650v1

*Relevance score: 11.0*

---

## 26. Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from Gasing Literacy Learning System

**Authors:** H. Situngkir, A. B. Lumbantobing, Y. Surya

**Source:** arxiv • 2026-01-14

**Summary:** This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable...

**Links:**
- Landing page: http://arxiv.org/abs/2601.11643v1
- PDF: https://arxiv.org/pdf/2601.11643v1

*Relevance score: 11.0*

---

## 27. When Generative AI Meets Extended Reality: Enabling Scalable and Natural Interactions

**Authors:** Mingyu Zhu, Jiangong Chen, Bin Li

**Source:** arxiv • 2026-01-13

**Summary:** Extended Reality (XR), including virtual, augmented, and mixed reality, provides immersive and interactive experiences across diverse applications, from VR-based education to AR-based assistance and MR-based training. However, widespread XR adoption remains limited due to two key challenges: 1) the ...

**Links:**
- Landing page: http://arxiv.org/abs/2601.15308v1
- PDF: https://arxiv.org/pdf/2601.15308v1
- DOI: https://doi.org/10.1109/MIC.2025.3619462

*Relevance score: 11.0*

---

## 28. ALIGNAgent: Adaptive Learner Intelligence for Gap Identification and Next-step guidance

**Authors:** Bismack Tokoli, Luis Jaimes, Ayesha S. Dina

**Source:** arxiv • 2026-01-22

**Summary:** Personalized learning systems have emerged as a promising approach to enhance student outcomes by tailoring educational content, pacing, and feedback to individual needs. However, most existing systems remain fragmented, specializing in either knowledge tracing, diagnostic modeling, or resource reco...

**Links:**
- Landing page: http://arxiv.org/abs/2601.15551v1
- PDF: https://arxiv.org/pdf/2601.15551v1

*Relevance score: 9.0*

---

## 29. Language, Caste, and Context: Demographic Disparities in AI-Generated Explanations Across Indian and American STEM Educational Systems

**Authors:** Amogh Gupta, Niharika Patil, Sourojit Ghosh, SnehalKumar, S Gaikwad

**Source:** arxiv • 2026-01-20

**Summary:** The popularization of AI chatbot usage globally has created opportunities for research into their benefits and drawbacks, especially for students using AI assistants for coursework support. This paper asks: how do LLMs perceive the intellectual capabilities of student profiles from intersecting marg...

**Links:**
- Landing page: http://arxiv.org/abs/2601.14506v1
- PDF: https://arxiv.org/pdf/2601.14506v1

*Relevance score: 9.0*

---

## 30. Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment

**Authors:** Yuming Yang, Mingyoung Lai, Wanxu Zhao, Xiaoran Fan, Zhiheng Xi et al. (16 authors)

**Source:** arxiv • 2026-01-20

**Summary:** Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-st...

**Links:**
- Landing page: http://arxiv.org/abs/2601.14249v1
- PDF: https://arxiv.org/pdf/2601.14249v1

*Relevance score: 9.0*

---

## 31. Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education

**Authors:** Unggi Lee, Jahyun Jeong, Sunyoung Shin, Haeun Park, Jeongsu Moon et al. (15 authors)

**Source:** arxiv • 2026-01-20

**Summary:** Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sa...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13876v1
- PDF: https://arxiv.org/pdf/2601.13876v1

*Relevance score: 9.0*

---

## 32. Exploring Learners' Expectations and Engagement When Collaborating with Constructively Controversial Peer Agents

**Authors:** Thitaree Tanprasert, Young-ho Kim, Sidney Fels, Dongwook Yoon

**Source:** arxiv • 2026-01-20

**Summary:** Peer agents can supplement real-time collaborative learning in asynchronous online courses. Constructive Controversy (CC) theory suggests that humans deepen their understanding of a topic by confronting and resolving controversies. This study explores whether CC's benefits apply to LLM-based peer ag...

**Links:**
- Landing page: http://arxiv.org/abs/2601.13479v1
- PDF: https://arxiv.org/pdf/2601.13479v1

*Relevance score: 9.0*

---

## 33. Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?

**Authors:** Nafiz Imtiaz Khan, Kylie Cleland, Vladimir Filkov, Roger Eric Goldman

**Source:** arxiv • 2026-01-19

**Summary:** Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology ...

**Links:**
- Landing page: http://arxiv.org/abs/2601.12648v1
- PDF: https://arxiv.org/pdf/2601.12648v1

*Relevance score: 9.0*

---
